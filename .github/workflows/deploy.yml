name: Run Crawler

on:
  schedule:
    - cron: "0 */6 * * *"

jobs:
  deploy:
    name: Update Algolia Index
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: website
        shell: bash

    steps:
         # Checkout the code
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0
          
      - name: Check invalid redirect rules
        run: |
          incorrect_paths="$(jq -r '.redirects[] | select(.source == .destination) | .source' vercel.json)"
          if [[ -n $incorrect_paths ]]; then
            echo "There are redirect rules with source = destination. Please correct them." >&2
            echo "$incorrect_paths" >&2
            exit 1
          fi
          repeated_sources="$(jq -r '.redirects[].source' vercel.json | sort | uniq --count --repeated)"
          if [[ -n $repeated_sources ]]; then
            echo "There are repeated sources in redirect rules. Please correct them." >&2
            echo "$repeated_sources" >&2
            exit 1
          fi

      - name: Run Docker Container
        run: |
            docker run -e "APPLICATION_ID=${{ secrets.ALGOLIA_APPLICATION_ID }}" -e "ALGOLIA_API_KEY=${{ secrets.ALOGLIA_API_KEY }}" -e "CONFIG=$(cat config.json | jq -r tostring)" algolia/docsearch-scraper:latest
            