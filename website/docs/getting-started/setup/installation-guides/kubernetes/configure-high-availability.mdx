---
description: Follow these steps to configure high availability for Appsmith on Kubernetes.
---
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Configure High Availability for Appsmith on Kubernetes
The page provides steps to configure High Availability (HA) and Scalability for Appsmith on Kubernetes.

:::info
High Availability and Scalability is only available on Kubernetes self-hosted, [**Business Edition**](https://www.appsmith.com/pricing) instances of Appsmith.
:::

## Prerequisites
  1. Install `metrics-server`, which provides vital metrics to the Horizontal Pod Autoscaler (HPA) to scale the pods.

   ```bash
    kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
   ```

  2. PostgreSQL has to be enabled Or configure an external PostgreSQL in the `applicationConfig` section in `values.yaml`.

      1. Configure the parameters to enable PostgreSQL as shown below:

      ```yaml
            # enable PostgreSQL
            postgresql:
            # highlight-next-line
                enabled: true
                auth:
                  username: root
      ```

      2. Configure the parameters to point to an external PostgreSQL as shown below:
    
      ```yaml
        # configure an external PostgreSQL
        applicationConfig::
          APPSMITH_KEYCLOAK_DB_DRIVER: "postgresql"
          APPSMITH_KEYCLOAK_DB_USERNAME: "<POSTGRES_USER>"
          APPSMITH_KEYCLOAK_DB_PASSWORD: "<POSTGRES_PASSWORD>"
          APPSMITH_KEYCLOAK_DB_URL: "<POSTGRES_DB_URL>"
      ```

  3.  Enable MongoDB in the `values.yaml` or configure an external MongoDB in the `applicationConfig` in `values.yaml`.

      1. Configure the parameters to enable MongoDB as shown below:

        ```yaml
          # enable MongoDB
          mongodb:
            # highlight-next-line
            enabled: true
            service:
              nameOverride: appsmith-mongodb
        ```
      
      2. Configure the parameters to point to an external MongoDB as shown below:

        ```yaml
        # configure an external MongoDB
          applicationConfig::
            APPSMITH_MONGODB_URI: "<MONGODB_URI>"
        ```

## Configure instance
Follow the steps below to configure your instance:
1. Enable `autoscaling` in the `values.yaml`. The below shows the `autoscaling` configuration for the Appsmith Deployment:

   ```yaml
        autoscaling:
          # highlight-next-line
          enabled: true
          minReplicas: 2
          maxReplicas: 2
   ```

2. Create a shared file system. 

<Tabs groupId="configurations">
  <TabItem label="AWS EKS" value="AWSEKS">

The [Amazon EFS Container Storage Interface (CSI)](https://docs.aws.amazon.com/eks/latest/userguide/efs-csi.html) driver is a plugin for the Kubernetes container orchestration system that enables you to mount [Amazon Elastic File System (EFS)](https://aws.amazon.com/efs/) on Kubernetes pods. Using the EFS CSI driver, you can create a shared file system on Kubernetes by mounting an EFS file system on the pods in your cluster. Follow the steps available at the official [EFS CSI driver documentation](https://docs.aws.amazon.com/eks/latest/userguide/efs-csi.html) to mount EFS on the Kubernetes pods.

</TabItem>
</Tabs>

3. To configure persistence, you can use persistent volumes, persistent volume claims, or storage classes, depending on your platform. 

<Tabs groupId="configurations">
  <TabItem label="AWS EKS" value="AWSEKS">

You have the option to either configure EFS using a new [Persistent Volume Claim (PVC)](https://kubernetes.io/docs/concepts/storage/persistent-volumes/) or using an existing PVC.

  1. Using new PVC
  This is useful when you don't have any existing PVC available or if you want to dedicate a specific PVC solely for EFS. Once the PVC is created, ensure that the following configuration is updated in `values.yaml` file under `persistence` attribute as shown below:

  ```yaml
    existingClaim:
      enabled: false
      name: 
      claimName: 
    efs:
      # highlight-next-line
      enabled: true
      driver: efs.csi.aws.com
      # highlight-next-line
      volumeHandle: <FILE_SYSTEM_ID>
  ```

  2. Using existing PVC

  This is useful if you already have a PVC that you want to reuse for EFS or if you have multiple deployments or pods that need access to the same EFS volume. Ensure that the following configuration is updated in `values.yaml` file under `persistence` attribute as shown below:

  ```yaml
  existingClaim:
      # highlight-next-line
      enabled: true
      name: efsappsmith
      claimName: efsappsmith
    efs:
      enabled: true
      driver: efs.csi.aws.com
      volumeHandle: <FILE_SYSTEM_ID>
  ```

</TabItem>
<TabItem label="Minikube" value="Minikube">
   
  To configure persistence in Minikube, ensure that you have set the properties in `values.yaml` file under `persistence` attribute as shown below.

  ```yaml
    localCluster:
      - minikube
    ## @param persistence.accessModes PV Access Mode
    ##
    accessModes:
      - ReadWriteMany
    ## @param persistence.size PVC Storage Request
    ##
    size: 10Gi
    ## Fine tuning for volumeClaimTemplates
    ##
    existingClaim:
      # highlight-next-line
      enabled: false
      name:
      claimName:
    ReclaimPolicy: Retain
    efs:
      # highlight-next-line
      enabled: false
      driver: 
      volumeHandle:
  ```

</TabItem>
</Tabs>

## Troubleshooting
If you continue to face issues, reach out to [support@appsmith.com](mailto:support@appsmith.com).

## Further reading
* [Configure Appsmith instance](/getting-started/setup/instance-configuration#configure-helm-installations)
* [Manage Appsmith instance](/getting-started/setup/instance-management/)